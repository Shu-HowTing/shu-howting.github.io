+++
# author = "丁树浩"
title = "长序列建模"
date = "2024-09-02"
description = "推荐中的长序列建模"
tags = [
  "推荐",
  "长序列"
]
categories = [
  "RecSys"
]
draft = false
math = true
+++

> 推荐模型中，序列建模是一个重要话题。如$DIN$、$BST$等都已经成为经典模型。但是这些模型都是聚焦在用户的短期（实时）兴趣，对于用户的长期兴趣无法精确捕捉。这个时候，就需要对用户的长期行为序列进行建模。

## 长序列建模

长序列一般是指规模在千或者万级别的行为序列。对于这种级别的序列进行建模的难点在于，计算时间复杂度高，开销大，对线上服务的计算延迟提出了很大的挑战。所以研究的重点大多集中在如何降低模型的复杂度，以满足线上服务的延时要求。

业内一般是使用两阶段(**泛搜索+精准排序**)建模方案， 首先先从用户长序列中检索出与目标Item相近的$top-k$个行为， 再用这$top-k$个行为组成序列与目标Item做Target Attention。两阶段建模需要考虑检索效率以及两阶段的一致性， 比较有代表性的工作有阿里的SIM和ETA， 美团的SDIM，以及快手的TWIN， 下面分别介绍这些方法。

### SIM

SIM是一种级联的两阶段建模方案， 第1阶段使用泛搜索单元(General Search Unit， 简称GSU)从用户行为长序列中检索出$top-k$个行为组成序列， 第2阶段使用抽取搜索单元(Exact Search Unit， 简称ESU)进行精细化用户兴趣建模， 其整体框架如下图所示:
![](https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/202409111618947.png)

#### GSU
SIM给出了两种从长序列中搜索$top-k$行为的实现方式: $Hard\ Search$和$Soft\ Search$。通常来说， $Hard\ Search实$现简单， 线上性能更强， 而$Soft\ Search$上限更高， 对工程基建会有一定的要求。论文里， 尽管$Soft\ Search$的离线效果稍微好一些， 但权衡收益和资源消耗， 淘宝最终使用$Hard\ Search$部署SIM， 下面分别介绍两种实现方法。

- $Hard\ Search$
![](https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/202409111622198.png)

给定要预测打分的目标Item， $Hard\ Search$是直接基于给定规则(如相同类目)从用户行为序列中， 筛选出与当前目标Item符合同一规则结果的行为子序列， 如论文里淘宝是使用相同类目ID进行筛选。

- $Soft\ Search$
![](https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/202409111626309.png)

$Soft\ Search$是对用户行为和候选Item向量化后, 使用向量化$top-k$检索。考虑到长期用户行为的分布和短期用户行为的分布不一致，直接使用CTR模型中短期行为学习到的embedding进行检索(I2I)，会有一定的误导。 因此, 这里会使用超长的用户行为序列, 作为CTR的一个辅助任务联合训练得到。其核心就是将life long行为序列做sum pooling进行concat起来, 如图所示。

#### ESU
ESU会对GSU中提取的$top-k$用户行为序列，进行建模得到用户的长期兴趣表征, 如下图的橙色部分所示:

![](https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/202409111625525.png)

考虑到长期行为的时间跨度较长，历史行为与当前行为的时间间隔也是一个重要的因素，因此，ESU 首先将时间间隔 $\mathbf{D}=\left[\Delta_1 \; \Delta_2 \; \ldots \; \Delta_K\right]$ 映射得到时间间隔embedding表征，
再将它与对应的用户行为embedding进行concate起来作为用户每个长期历史行为表征。

### ETA
基于SIM的长序列建模方案, 分成**GSU泛搜索+ESU精准排序**两个阶段, 这两个阶段之间存在一定的Gap:

- 基于Hard Search方法两阶段的目标不一致: Hard Search使用类目ID进行检索, 与CTR预估任务关系不那么直接
- 基于Soft Search方法两阶段模型的更新频率不一: CTR预估一般是在线学习方式持续更新的, 而Soft Search的embedding索引是离线(如天级/小时级)更新的

因此, 作者希望以一种$End-to-End$方式进行长序列的建模。既然GSU因为有辅助任务和模型, 导致两阶段不一致，那可以把GSU的过程也整合进ESU的模型中。

同时, 为了缓解$End-to-End$带来的性能问题, 可以再使用局部敏感哈希（$SimHash$）加速查询过程。

ETA(End-to-end Target Attention)的整体框架如下图所示, 最核心的是使用SimHash算法从长序列中$top-k$个Item的检索, 其余部分和SIM没有太大差异。

![](https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/202409111641786.png)

离线训练时, ETA会通过SimHash算法(事先随机选择个hash函数)，为打分商品和用户历史行为长序列生成Hash签名, 使用Int64来存储二进制签名, 通过汉明距离从中调选出$top-k$个Item, 用于后续的Target Attention计算, 这个过程是一个End-to-End的。

在线推理时, 会预先计算SimHash签名, 节省计算过程。在构建模型索引时, 通过Offline2Online的方式对Item表预计算, 并存储在Embedding lookup table中, 把生成签名的过程转化为在内存查表，大大减少计算复杂度。


#### SimHash原理
![](https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/202409111643800.png)

## SDIM

#### Motivation
[TODO]


## TWIN
[TODO]