<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>推荐 on White</title>
    <link>http://localhost:1313/tags/%E6%8E%A8%E8%8D%90/</link>
    <description>Recent content in 推荐 on White</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 05 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E6%8E%A8%E8%8D%90/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>当推荐遇到大模型</title>
      <link>http://localhost:1313/post/recsys/%E5%BD%93%E6%8E%A8%E8%8D%90%E9%81%87%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 05 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/%E5%BD%93%E6%8E%A8%E8%8D%90%E9%81%87%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/</guid>
      <description>自从大语言模型爆火之后，大家对大语言模型（LLM）如何成功应用在推荐系统进行了不少尝试。本文是对目前一些业界工作的调研和总结。 大模型应用范式 现阶段，经典推荐架构基本遵循以下范式： 目前, LLM 在推荐系统中的主流应用可以分为两种范式: 一个是作为经典推荐系统的辅助部分，即 LLM+RS。 一个是 LLM 单独作为一个完整的推荐系统，即 LLM AS RS。 本文接下来将分别介绍这两种应用方式。 LLM+RS 传统推荐系统经过多年发展，从召回、排序</description>
    </item>
    <item>
      <title>Batch内负采样</title>
      <link>http://localhost:1313/post/recsys/Batch%E8%B4%9F%E9%87%87%E6%A0%B7/</link>
      <pubDate>Sat, 02 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/Batch%E8%B4%9F%E9%87%87%E6%A0%B7/</guid>
      <description>In-batch Negative Sampling code: 1import torch 2import torch.nn as nn 3import torch.nn.functional as F 4 5class RecommenderModel(nn.Module): 6 def __init__(self, user_size, item_size, embedding_dim): 7 super(RecommenderModel, self).__init__() 8 self.user_embedding = nn.Embedding(user_size, embedding_dim) 9 self.item_embedding = nn.Embedding(item_size, embedding_dim) 10 11 def forward(self, user_ids, item_ids): 12 user_embeds = self.user_embedding(user_ids) 13 item_embeds = self.item_embedding(item_ids) 14 return user_embeds, item_embeds 15 16 def in_batch_negative_sampling_loss(user_embeds, item_embeds): 17 batch_size = user_embeds.size(0) 18 19 # 正样本得分 (batch_size,) 20 positive_scores = torch.sum(user_embeds * item_embeds, dim=-1) 21 22 # 负样本得分 (batch_size, batch_size) 23 negative_scores = torch.matmul(user_embeds, item_embeds.t()) 24 25 # 创建标签 (batch_size, batch_size) 26 labels = torch.eye(batch_size).to(user_embeds.device) 27 28 # 计算损失 29 loss = F.cross_entropy(negative_scores, labels.argmax(dim=-1)) 30 31 return loss 32 33# 示例数据 34batch_size = 4 35embedding_dim = 8 36user_size = 100 37item_size = 1000 38 39user_ids = torch.randint(0, user_size, (batch_size,)) 40item_ids = torch.randint(0, item_size, (batch_size,)) 41 42model = RecommenderModel(user_size, item_size, embedding_dim) 43user_embeds, item_embeds = model(user_ids, item_ids) 44 45loss = in_batch_negative_sampling_loss(user_embeds, item_embeds) 46print(f&amp;#39;Loss: {loss.item()}&amp;#39;) 优点 效性：批量内负采样能够充分利用每个训练批次中的样本，提高</description>
    </item>
    <item>
      <title>动态权重在推荐中的应用</title>
      <link>http://localhost:1313/post/recsys/%E5%8A%A8%E6%80%81%E6%9D%83%E9%87%8D/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/%E5%8A%A8%E6%80%81%E6%9D%83%E9%87%8D/</guid>
      <description>动态权重 1. 从LHUC说起 语音识别领域2016年一项开创性工作提出了LHUC(Learning Hidden Unit Contribution)算法, 在DNN网络中为每个speaker学习对应的hidden unit contribution， 然后与common hidden layer相结合，以此提升不同speaker的语音识别准确率。这项工作属于domain adaptation领域，LHUC方法相比之前工作最重要的改进点是模型实现doma</description>
    </item>
    <item>
      <title>POSO冷启动</title>
      <link>http://localhost:1313/post/recsys/POSO%E5%86%B7%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/POSO%E5%86%B7%E5%90%AF%E5%8A%A8/</guid>
      <description>POSO POSO: Personalized Cold Start Modules for Large-scale Recommender Systems 是快手发表的一篇关于如何解决新老用户分群的文章。与传统的做法从样本上做文章不同，论文直接从模型结构上入手，希望模型能够区分两部分人群，达到一个新用户冷的效果。 Motivation 文章先分析了新用户和普通用户行为的存在差异性，然后设计实验可视化了新用户特征被淹没的现象，再提出了可嵌入到主流网络结构中的方法POSO。 按照常规的做法，一个模型想要hold住两种不一样的分布(新用户 &amp;amp;&amp;amp; 老用户)，至少得有一</description>
    </item>
    <item>
      <title>推荐中的特征交叉技术</title>
      <link>http://localhost:1313/post/recsys/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/</link>
      <pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/</guid>
      <description>特征交叉范式 特征交叉指的是通过组合两个（或多个）特征来学习特征间非线性的组合高阶表达，其收益则是来自通过挖掘特征之间的共现组合，拓展了特征输入的表达，从而使得模型能更容易学习到共现组合提供的信息。 业界实现方案可以主要分为非参数化方案和参数化方案。 非参数化方案：显式的表达特征交叉ID，例如特征求交，笛卡尔积特征等。 参数化方案：主要通过模型参数隐式拟合的形式去捕捉特征的非线性组合能力，而参数化方案在D</description>
    </item>
    <item>
      <title>召回模型的评估</title>
      <link>http://localhost:1313/post/recsys/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0/</link>
      <pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0/</guid>
      <description>召回模型评测指标 为什么不用AUC指标 AUC指标不适用于衡量召回模型。原因有三： 计算AUC时，正样本容易获得，可以拿点击样本做正样本。但负样本从哪里来？照搬精排，用曝光未点击做负样本，行不行？不行。否则，测试样本都来自曝光物料，也就是从系统筛选过的、比较匹配用户爱好的优质物料，这样的测试数据明显与召回的实际应用场景（海量的、和用户毫不相关的物料）有着天壤之别。失真的测试环境只能产生失真的指标，不能反</description>
    </item>
    <item>
      <title>多兴趣召回推荐</title>
      <link>http://localhost:1313/post/recsys/%E5%A4%9A%E5%85%B4%E8%B6%A3%E5%8F%AC%E5%9B%9E%E6%8E%A8%E8%8D%90/</link>
      <pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/%E5%A4%9A%E5%85%B4%E8%B6%A3%E5%8F%AC%E5%9B%9E%E6%8E%A8%E8%8D%90/</guid>
      <description>传统双塔 user_tower: 产生$V_u$ item_tower: 产生$V_i$ $$ score = f(u\_emb, i\_emb)= &amp;lt;V_u, V_i&amp;gt; $$ 多兴趣双塔 MIND 1interest_capsules = CapsuleLayer(input_units=user_seq_embedding.shape[-1], 2 out_units=params[&amp;#39;embedding_dim&amp;#39;], 3 max_len=params[&amp;#39;max_seq_len&amp;#39;], 4 k_max=params[&amp;#39;k_max&amp;#39;], 5 mode=mode)((user_seq_embedding, like_user_seq_len)) # [B, k_max, embedding_dim] 6 7q_embedding_layer = tf.tile(tf.expand_dims(q_embedding, -2), [1, params[&amp;#39;k_max&amp;#39;], 1]) # [B, k_max, 64] 8 9q_deep_input = tf.concat([q_embedding_layer, interest_capsules], axis=-1) # [B, k_max, embedding_dim+64] $Dynamic \ \ Routing$ $Loss$: $$ \begin{aligned} \overrightarrow{\boldsymbol{\upsilon}}_{u} &amp;amp;=\mathrm{Attention}\left(\overrightarrow{\boldsymbol{e}}_{i},\mathrm{V}_{u},\mathrm{V}_{u}\right) \\ &amp;amp;=\mathrm{V}_{u}\mathrm{softmax}(\mathrm{pow}(\mathrm{V}_{u}^{\mathrm{T}}\overrightarrow{\boldsymbol{e}}_{i},p)) \end{aligned} $$ ComiRec $Dynamic \ \ Routing$提取兴趣 $Attention$机制提取兴趣 $$ \mathbf{A}=\mathrm{softmax}(\mathbf{W}_{2}^{\top}\tanh(\mathbf{W}_{1}\mathbf{H}))^{\top} \\ \mathbf{V}_{u}=\mathbf{HA} $$ $\mathrm{H}\in \mathbb{R}^{d \times n}$ $\mathrm{where~}n\mathrm{~is~the~length~of~user~sequence}$ $\mathbf{V}_{u}=[\mathbf{v}_{1},&amp;hellip;,\mathbf{v}_{K}]\in\mathbb{R}^{d\times K}$ : $K个user \ \ emb$ $Loss$: $$ \mathbf{v}_u=\mathbf{V}_u[:,\mathrm{argmax}(\mathbf{V}_u^\top\mathbf{e}_i)], \\ P_\theta(i|u)=\frac{\exp(\mathbf{v}_u^\top\mathbf{e}_i)}{\sum_{k\in I}\exp(\mathbf{v}_u^\top\mathbf{e}_k)}. $$ $Reference: $ MIND网络多兴趣提取</description>
    </item>
    <item>
      <title>推荐算法中的序列特征处理</title>
      <link>http://localhost:1313/post/recsys/seq_feat/</link>
      <pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/recsys/seq_feat/</guid>
      <description>在推荐领域中，行为序列特征是一种极为重要的特征。近年来，出现了很多有关行为序列特征建模的论文，研究如何将行为序列特征应用到推荐场景中，以更好挖掘用户的历史兴趣。本文将带大家梳理介绍这些论文中提出的方法。 序列特征 序列特征通常表现为时间上的跨度，具有很强的时间先后关系。如何在行为序列中挖掘用户兴趣的多样性以及实效性，是序列特模型研究的重点。 序列特征处理方法 本文将聚焦于$Pooling、attentio</description>
    </item>
  </channel>
</rss>
