<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <meta name="referrer" content="no-referrer-when-downgrade">
    

    <title>Posts | White</title>
    <meta property="og:title" content="Posts - White">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="DS, DeepLearning">
    <meta name="description" content="Posts">
        
    <meta name="author" content="whiteding">
    <meta property="og:url" content="https://whiteding.fun/post/">
    <link rel="shortcut icon" href='/favicon.ico'  type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml" href="https://whiteding.fun/post/index.xml" title="White" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
        <link rel="stylesheet" href='/css/douban.css'>
    
        <link rel="stylesheet" href='/css/other.css'>
    

    
    


</head>

<body>
    
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://whiteding.fun/">
                        White
                    </a>
                
                <p class="description">Stay foolish, Stay hungry!</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class=" current" href="https://whiteding.fun/"> <i class="fas fa-home"></i> Home</a>
                    
                    <a  href="/categories/" title="&lt;i class=&#39;fas fa-layer-group&#39;&gt;&lt;/i&gt; 分类" > <i class='fas fa-layer-group'></i> 分类</a>
                    
                    
                    <a  href="/tags/" title="&lt;i class=&#39;fas fa-tag&#39;&gt;&lt;/i&gt; 标签" > <i class='fas fa-tag'></i> 标签</a>
                    
                    
                    <a  href="/archives/" title="&lt;i class=&#39;fas fa-archive&#39;&gt;&lt;/i&gt; 归档" > <i class='fas fa-archive'></i> 归档</a>
                    
                    
                    <a  href="/about/" title="&lt;i class=&#39;fas fa-user&#39;&gt;&lt;/i&gt; 关于" > <i class='fas fa-user'></i> 关于</a>
                    
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/recsys/llm/" title="当推荐遇到大模型" target="_blank">当推荐遇到大模型</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2024-07-01T00:00:00Z" class="post-meta meta-date dt-published">
    2024-07-01
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/RecSys' target="_blank">RecSys</a>
  
</div>


        <div class="post-content">
            自从大语言模型爆火之后，大家对大语言模型（LLM）如何成功应用在推荐系统进行了不少尝试。本文是对目前一些业界工作的调研和总结。 大模型应用范式 经典的推荐架构基本遵循以下范式： 目前, LLM 在推荐系统中的主流应用可以分为两种范式: 一个是作为经典推荐系统的辅助部分，即 LLM+RS。 一个是 LLM 单独作为一个完整的推荐系统，即 LLM AS RS。 本文接下来将分别介绍这两种应用方式。 LLM+RS 传统推荐系统经过多年发展，从召回、排序、重排……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/recsys/llm/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/recsys/Batch%E8%B4%9F%E9%87%87%E6%A0%B7/" title="Batch内负采样" target="_blank">Batch内负采样</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2024-04-02T00:00:00Z" class="post-meta meta-date dt-published">
    2024-04-02
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/RecSys' target="_blank">RecSys</a>
  
</div>


        <div class="post-content">
            In-batch Negative Sampling code: 1import torch 2import torch.nn as nn 3import torch.nn.functional as F 4 5class RecommenderModel(nn.Module): 6 def __init__(self, user_size, item_size, embedding_dim): 7 super(RecommenderModel, self).__init__() 8 self.user_embedding = nn.Embedding(user_size, embedding_dim) 9 self.item_embedding = nn.Embedding(item_size, embedding_dim) 10 11 def forward(self, user_ids, item_ids): 12 user_embeds = self.user_embedding(user_ids) 13 item_embeds = self.item_embedding(item_ids) 14 return user_embeds, item_embeds 15 16 def in_batch_negative_sampling_loss(user_embeds, item_embeds): 17 batch_size = user_embeds.size(0) 18 19 # 正样本得分 20 positive_scores = torch.sum(user_embeds * item_embeds, dim=-1) # (batch_size,) 21 22 # 负样本得分 23 negative_scores = torch.matmul(user_embeds, item_embeds.t()) # (batch_size, batch_size) 24 25 # 创建标签 26 labels = torch.eye(batch_size).to(user_embeds.device) # (batch_size, batch_size) 27 28 # 计算损失 29 loss = F.cross_entropy(negative_scores, labels.argmax(dim=-1)) 30 31 return loss 32 33# 示例数据 34batch_size = 4 35embedding_dim = 8 36user_size = 100 37item_size = 1000 38 39user_ids = torch.randint(0, user_size, (batch_size,)) 40item_ids = torch.randint(0, item_size, (batch_size,)) 41 42model = RecommenderModel(user_size, item_size, embedding_dim) 43user_embeds, item_embeds = model(user_ids, item_ids) 44 45loss = in_batch_negative_sampling_loss(user_embeds, item_embeds) 46print(f&#39;Loss: {loss.item()}&#39;) 优点 效性：批量内负采样能够充分利用每个训练批次中的样本……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/recsys/Batch%E8%B4%9F%E9%87%87%E6%A0%B7/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/recsys/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0/" title="召回模型的评估" target="_blank">召回模型的评估</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2023-07-02T00:00:00Z" class="post-meta meta-date dt-published">
    2023-07-02
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/RecSys' target="_blank">RecSys</a>
  
</div>


        <div class="post-content">
            召回模型评测指标 为什么不用AUC指标 AUC指标不适用于衡量召回模型。原因有三： 计算AUC时，正样本容易获得，可以拿点击样本做正样本。但负样本从哪里来？照搬精排，用曝光未点击做负样本，行不行？不行。否则，测试样本都来自曝光物料，也就是从系统筛选过的、比较匹配用户爱好的优质物料，这样的测试数据明显与召回的实际应用场景（海量的、和用户毫不相关的物料）有着天壤之别。失真的测试环境只能产生失真的指标，不能反……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/recsys/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/recsys/%E5%A4%9A%E5%85%B4%E8%B6%A3%E5%8F%AC%E5%9B%9E%E6%8E%A8%E8%8D%90/" title="多兴趣召回推荐" target="_blank">多兴趣召回推荐</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2023-06-15T00:00:00Z" class="post-meta meta-date dt-published">
    2023-06-15
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/RecSys' target="_blank">RecSys</a>
  
</div>


        <div class="post-content">
            传统双塔 user_tower: 产生$V_u$ item_tower: 产生$V_i$ $$ score = f(u\_emb, i\_emb)= &lt;V_u, V_i&gt; $$ 多兴趣双塔 MIND 1interest_capsules = CapsuleLayer(input_units=user_seq_embedding.shape[-1], 2 out_units=params[&#39;embedding_dim&#39;], 3 max_len=params[&#39;max_seq_len&#39;], 4 k_max=params[&#39;k_max&#39;], 5 mode=mode)((user_seq_embedding, like_user_seq_len)) # [B, k_max, embedding_dim] 6 7q_embedding_layer = tf.tile(tf.expand_dims(q_embedding, -2), [1, params[&#39;k_max&#39;], 1]) # [B, k_max, 64] 8 9q_deep_input = tf.concat([q_embedding_layer, interest_capsules], axis=-1) # [B, k_max, embedding_dim+64] $Dynamic \ \ Routing$ $Loss$: $$ \begin{aligned} \overrightarrow{\boldsymbol{\upsilon}}_{u} &amp;=\mathrm{Attention}\left(\overrightarrow{\boldsymbol{e}}_{i},\mathrm{V}_{u},\mathrm{V}_{u}\right) \\ &amp;=\mathrm{V}_{u}\mathrm{softmax}(\mathrm{pow}(\mathrm{V}_{u}^{\mathrm{T}}\overrightarrow{\boldsymbol{e}}_{i},p)) \end{aligned} $$ ComiRec $Dynamic \ \ Routing$提取兴趣 $Attention$机制提取兴趣 $$ \mathbf{A}=\mathrm{softmax}(\mathbf{W}_{2}^{\top}\tanh(\mathbf{W}_{1}\mathbf{H}))^{\top} \\ \mathbf{V}_{u}=\mathbf{HA} $$ $\mathrm{H}\in \mathbb{R}^{d \times n}$ $\mathrm{where~}n\mathrm{~is~the~length~of~user~sequence}$ $\mathbf{V}_{u}=[\mathbf{v}_{1},&hellip;,\mathbf{v}_{K}]\in\mathbb{R}^{d\times K}$ : $K个user \ \ emb$ $Loss$: $$ \mathbf{v}_u=\mathbf{V}_u[:,\mathrm{argmax}(\mathbf{V}_u^\top\mathbf{e}_i)], \\ P_\theta(i|u)=\frac{\exp(\mathbf{v}_u^\top\mathbf{e}_i)}{\sum_{k\in I}\exp(\mathbf{v}_u^\top\mathbf{e}_k)}. $$ $Reference: $ MIND网络多兴趣提取……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/recsys/%E5%A4%9A%E5%85%B4%E8%B6%A3%E5%8F%AC%E5%9B%9E%E6%8E%A8%E8%8D%90/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/recsys/seq_feat/" title="推荐算法中的序列特征模型" target="_blank">推荐算法中的序列特征模型</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2022-02-08T00:00:00Z" class="post-meta meta-date dt-published">
    2022-02-08
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/RecSys' target="_blank">RecSys</a>
  
</div>


        <div class="post-content">
            在推荐领域中，行为序列特征是一种极为重要的特征。近年来，出现了很多有关行为序列特征建模的论文，研究如何将行为序列特征应用到推荐场景中，以更好挖掘用户的历史兴趣。本文将带大家梳理介绍这些论文中提出的方法。 序列特征 序列特征通常表现为时间上的跨度，具有很强的时间先后关系。如何在行为序列中挖掘用户兴趣的多样性以及实效性，是序列特模型研究的重点。 序列特征模型 按时间来看，推荐算法中的序列特征模型经历了$Poo……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/recsys/seq_feat/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/machine_learning/softmax%E8%AE%A1%E7%AE%97%E4%BC%98%E5%8C%96/" title="softmax计算优化" target="_blank">softmax计算优化</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2021-12-01T00:00:00Z" class="post-meta meta-date dt-published">
    2021-12-01
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/machine-learning' target="_blank">machine learning</a>
  
</div>


        <div class="post-content">
            softmax上溢和下溢问题 解决这个问题的方法就是利用softmax的冗余性。我们可以看到对于任意一个数$a$, $x-a$和$x$在$softmax$中的结果都是一样的。 $$ \frac{\exp^{(x-a)}}{\sum_{i=1}^k \exp_i^{(x-a)}}=\frac{\exp ^{(x)} \exp ^{(-a)}}{\exp ^{(-a)} \sum_{i=1}^k \exp _i^{(x)}}=\frac{\exp ^{(x)}}{\sum_{i=1}^k \exp_i^{(x)}} $$ 对于一组输入，我们可以让a=max(x). 这样就可以保证x-a的最大值等于0，也就不会产生上溢的问题。同时，因为$x-a=0$, 所以$exp(0)=1$,分母就不可能为0。 $$ \begin{array}{l} \log \left(\frac{\exp^{(x-a)}}{\sum_{i=1}^k \exp_i^{(x-a)}}\right) &amp;=\log \left(e^{(x-a)}\right)-\log \left(\sum_{i=1}^k \exp_i^{(x-a)}\right) \\ &amp;=(x-a)-\log \left(\sum_{i=1}^k \exp_i^{(x-a)}\right) \end{array} $$……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/machine_learning/softmax%E8%AE%A1%E7%AE%97%E4%BC%98%E5%8C%96/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/machine_learning/XGBoost%E7%9A%84%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E5%AE%9E%E8%B7%B5/" title="XGBoost的原理分析以及实践" target="_blank">XGBoost的原理分析以及实践</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2021-09-01T00:00:00Z" class="post-meta meta-date dt-published">
    2021-09-01
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/machine-learning' target="_blank">machine learning</a>
  
</div>


        <div class="post-content">
            XGBoost算法 原理 任何机器学习的问题都可以从目标函数(objective function)出发，目标函数的主要由两部分组成 $损失函数+正则项$： $$ Obj(\Theta)=L(\Theta)+\Omega(\Theta) $$ 在这里，当我选择树模型为基学习器时，我们需要正则的对象，或者说需要控制复杂度的对象就是这K颗树,通常树的参数有树的深度，叶子节点的个数，叶子节点值的取值（xgboost里称为权重weight)。 所以，我们的目标函数形式如下： $$ \mathcal{L}=\sum_{i} l\left(\hat{y_i}, y_{i}\right)+\sum_{k} \Omega\left(f_{k}\right) $$ 这里前一半……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/machine_learning/XGBoost%E7%9A%84%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E5%AE%9E%E8%B7%B5/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/statistics/Beta%E5%88%86%E5%B8%83%E5%92%8CThompson%E9%87%87%E6%A0%B7/" title="Beta分布和Thompson采样" target="_blank">Beta分布和Thompson采样</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2021-03-06T00:00:00Z" class="post-meta meta-date dt-published">
    2021-03-06
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6' target="_blank">统计学</a>
  
</div>


        <div class="post-content">
            $Beta$分布 $Beta$分布是一个定义在[0,1]区间上的连续概率分布族，它有两个正值参数，称为形状参数，一般用$\alpha$和$\beta$表示 $Beta$分布的概率密度为： $$ f(x ; \alpha, \beta)=\frac{x^{\alpha-1}(1-x)^{\beta-1}}{\int_{0}^{1} u^{\alpha-1}(1-u)^{\beta-1} d u}=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1}=\frac{1}{B(\alpha, \beta)} x^{\alpha-1}(1-x)^{\beta-1} $$ 随机变量$X$服从参数为$\alpha, \beta$的$beta$分布，一般记作： $$ X \sim \operatorname {Beta} (\alpha, \beta) $$ $Beta$分布的期望： $$ \frac{\alpha}{\alpha + \beta} $$ $Beta$分布的方差： $$ \frac{\alpha \beta}{(\alpha+\beta)^{2}(\alpha+\beta+1)} $$ $Beta$分布的概率密度图……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/statistics/Beta%E5%88%86%E5%B8%83%E5%92%8CThompson%E9%87%87%E6%A0%B7/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/kafka/Kafka%E6%A6%82%E8%BF%B0/" title="Kafka入门" target="_blank">Kafka入门</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2020-09-02T00:00:00Z" class="post-meta meta-date dt-published">
    2020-09-02
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/kafka' target="_blank">kafka</a>
  
</div>


        <div class="post-content">
            Kafka基本概念 Kafka 是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 1. 消息队列(MQ) 1.1 优点 解耦 削封 缓冲 异步通信 1.2 两种模式 点对点(一对一，消费者主动拉取数据，消息收到后消息清除) ​ 消息生产者生产消息发送到Queue中，然后消息消费者主动从Queue中取出并且消费消息。消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/kafka/Kafka%E6%A6%82%E8%BF%B0/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/flink/FLink%E6%B5%81%E5%A4%84%E7%90%86API/" title="Flink流处理入门" target="_blank">Flink流处理入门</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2020-08-25T00:00:00Z" class="post-meta meta-date dt-published">
    2020-08-25
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/flink' target="_blank">flink</a>
  
</div>


        <div class="post-content">
            Flink 流处理API 1. Environment 1.1 getExecutionEnvironment 创建一个执行环境，表示当前执行程序的上下文。如果程序是独立调用的，则此方法返回本地执行环境；如果从命令行客户端调用程序以提交到集群，则此方法返回此集群的执行环境，也就是说，getExecutionEnvironment会根据查询运行的方式决定返回什么样的运行环境，是最常用的一种创建执行环境的方式。 1ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); 2StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); 1.2 createLocalEnvironment 1LocalStreamEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(1); 1.3 createRemoteEnvironment 1StreamExecutionEnvironment env = StreamExecutionEnvironment.createRemoteEnvironment(&#34;jobmanage-hostname&#34;, 6123,&#34;YOURPATH//WordCount.jar&#34;); 2. Source 2.1 集合 1StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); 2env.setParallelism(1); 3 4// 从集合里读取数……
        </div>
        <p class="readmore"><a href="https://whiteding.fun/post/flink/FLink%E6%B5%81%E5%A4%84%E7%90%86API/" target="_blank"> 阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
    </article>
    
    
    



<ol class="page-navigator">
    

    
    <li  class="current">
        <a href="https://whiteding.fun/post/">1</a>
    </li>
    
    <li >
        <a href="https://whiteding.fun/post/page/2/">2</a>
    </li>
    
    <li >
        <a href="https://whiteding.fun/post/page/3/">3</a>
    </li>
    

    
    <li class="next">
        <a href="https://whiteding.fun/post/page/2/">Next</a>
    </li>
    
</ol>



</div>

                    <footer id="footer">
    <div>
        &copy; 2024 <a href="https://whiteding.fun/">White By whiteding</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>










    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




    <script src='/js/douban.js'></script>




                </div>

                <div id="secondary">
    
    

    <section class="widget">
        
<div class="avatar-widget">
    <img src="/img/avatar3.png" alt="Avatar" class="avatar-image">

    <p class="avatar-slogan">What's past is prologue.</p>
    <div class="widget-list" style="display: flex" >
        
        <li>
            <a class="info-icon" href="mailto:white_ding@163.com" title="email" target="_blank" style="margin-inline:5px">
                <i class="fa fa-envelope-square fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
        <li>
            <a class="info-icon" href="https://www.linkedin.com/in/white-ding-7b5151a7/" title="linkedin" target="_blank" style="margin-inline:5px">
                <i class="fab fa-linkedin fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
        <li>
            <a class="info-icon" href="https://github.com/Shu-HowTing" title="github" target="_blank" style="margin-inline:5px">
                <i class="fab fa-github fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
    </div>
</div>



    </section>

    <section class="widget">
        <h3 class="widget-title"> <i class="far fa-file"></i> Latest articles</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://whiteding.fun/post/recsys/llm/" title="当推荐遇到大模型" target="_blank">当推荐遇到大模型</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/Batch%E8%B4%9F%E9%87%87%E6%A0%B7/" title="Batch内负采样" target="_blank">Batch内负采样</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0/" title="召回模型的评估" target="_blank">召回模型的评估</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%A4%9A%E5%85%B4%E8%B6%A3%E5%8F%AC%E5%9B%9E%E6%8E%A8%E8%8D%90/" title="多兴趣召回推荐" target="_blank">多兴趣召回推荐</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/seq_feat/" title="推荐算法中的序列特征模型" target="_blank">推荐算法中的序列特征模型</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/machine_learning/softmax%E8%AE%A1%E7%AE%97%E4%BC%98%E5%8C%96/" title="softmax计算优化" target="_blank">softmax计算优化</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/machine_learning/XGBoost%E7%9A%84%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E5%AE%9E%E8%B7%B5/" title="XGBoost的原理分析以及实践" target="_blank">XGBoost的原理分析以及实践</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/statistics/Beta%E5%88%86%E5%B8%83%E5%92%8CThompson%E9%87%87%E6%A0%B7/" title="Beta分布和Thompson采样" target="_blank">Beta分布和Thompson采样</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/kafka/Kafka%E6%A6%82%E8%BF%B0/" title="Kafka入门" target="_blank">Kafka入门</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/flink/FLink%E6%B5%81%E5%A4%84%E7%90%86API/" title="Flink流处理入门" target="_blank">Flink流处理入门</a>
    </li>
    
</ul>
    </section>

     
    

    <section class="widget">
        <h3 class="widget-title"><a href='/categories/'> <i class="far fa-folder"></i> Categories</a></h3>
<ul class="widget-list">
    
    <li><a href="https://whiteding.fun/categories/flink/">Flink (1)</a></li>
    
    <li><a href="https://whiteding.fun/categories/kafka/">Kafka (1)</a></li>
    
    <li><a href="https://whiteding.fun/categories/machine-learning/">Machine Learning (2)</a></li>
    
    <li><a href="https://whiteding.fun/categories/RecSys/">RecSys (5)</a></li>
    
    <li><a href="https://whiteding.fun/categories/spark/">Spark (12)</a></li>
    
    <li><a href="https://whiteding.fun/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学 (1)</a></li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href='/tags/'> <i class="fas fa-tag"></i> Tags</a></h3>
<div class="tagcloud">
    
    <a href="https://whiteding.fun/tags/Beta%E5%88%86%E5%B8%83/">Beta分布</a>
    
    <a href="https://whiteding.fun/tags/flink/">Flink</a>
    
    <a href="https://whiteding.fun/tags/kafka/">Kafka</a>
    
    <a href="https://whiteding.fun/tags/softmax/">Softmax</a>
    
    <a href="https://whiteding.fun/tags/spark/">Spark</a>
    
    <a href="https://whiteding.fun/tags/Thompson/">Thompson</a>
    
    <a href="https://whiteding.fun/tags/xgb/">Xgb</a>
    
    <a href="https://whiteding.fun/tags/%E5%8F%AC%E5%9B%9E/">召回</a>
    
    <a href="https://whiteding.fun/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a>
    
    <a href="https://whiteding.fun/tags/%E5%BA%8F%E5%88%97%E7%89%B9%E5%BE%81/">序列特征</a>
    
    <a href="https://whiteding.fun/tags/%E6%8E%A8%E8%8D%90/">推荐</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title"> <i class="fas fa-external-link-alt"></i> Links</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="https://www.zhihu.com/people/ding-shu-hao" title="blog"> <i class="far fa-comment"></i> 知乎</a>
        </li>
        
    </ul>
</section>


    
</div>

            </div>
        </div>
    </div>

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
</body>

</html>