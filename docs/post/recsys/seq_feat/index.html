<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    

    <title>推荐算法中的序列特征处理 | White</title>
    <meta property="og:title" content="推荐算法中的序列特征处理 - White">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2022-02-08T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2022-02-08T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="DS, DeepLearning">
    <meta name="description" content="序列特征模型简介">
        
    <meta name="author" content="whiteding">
    <meta property="og:url" content="https://whiteding.fun/post/recsys/seq_feat/">
    <link rel="shortcut icon" href='/favicon.ico'  type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
        <link rel="stylesheet" href='/css/douban.css'>
    
        <link rel="stylesheet" href='/css/other.css'>
    

    
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@waline/client@v2/dist/waline.css">
        
    


</head>

<body>
    
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://whiteding.fun/">
                        White
                    </a>
                
                <p class="description">Stay foolish, Stay hungry!</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class=" current" href="https://whiteding.fun/"> <i class="fas fa-home"></i> Home</a>
                    
                    <a  href="/categories/" title="&lt;i class=&#39;fas fa-layer-group&#39;&gt;&lt;/i&gt; 分类" > <i class='fas fa-layer-group'></i> 分类</a>
                    
                    
                    <a  href="/tags/" title="&lt;i class=&#39;fas fa-tag&#39;&gt;&lt;/i&gt; 标签" > <i class='fas fa-tag'></i> 标签</a>
                    
                    
                    <a  href="/archives/" title="&lt;i class=&#39;fas fa-archive&#39;&gt;&lt;/i&gt; 归档" > <i class='fas fa-archive'></i> 归档</a>
                    
                    
                    <a  href="/about/" title="&lt;i class=&#39;fas fa-user&#39;&gt;&lt;/i&gt; 关于" > <i class='fas fa-user'></i> 关于</a>
                    
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    <style type="text/css">
    .post-toc {
        position: fixed;
        width: 200px;
        margin-left: -250px;
        padding: 5px 8px;
         
        font-family: serif;
        font-size: 12px;
        border: 1px solid rgba(0, 0, 0, .07);
        border-radius: 5px;
        background-color: rgba(255, 255, 255, 0.98);
        background-clip: padding-box;
        -webkit-box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        word-wrap: break-word;
        white-space: nowrap;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        z-index: 999;
        cursor: pointer;
        max-height: 70%;
        overflow-y: auto;
        overflow-x: hidden;
    }

    .post-toc .post-toc-title {
        width: 100%;
        margin: 10 auto;
        font-size: 16px;
        font-weight: 400;
        text-transform: uppercase;
        text-align: center;
        color: rgb(116, 69, 47);
    }

    .post-toc .post-toc-content {
        font-size: 14px;
         
    }

    .post-toc .post-toc-content>nav>ul {
        margin: 10px 10px;
    }

    .post-toc .post-toc-content ul {
        padding-left: 20px;
         
        margin: 0.5em;
        line-height: 1.8em;
        color: rgb(116, 69, 47);
    }

    .post-toc .post-toc-content ul ul {
        padding-left: 15px;
         
    }

    @media print,
    screen and (max-width:1057px) {
        .post-toc {
            display: none;
        }
    }
</style>
<div class="post-toc" style="position: absolute; top: 220px;">
    <h2 class="post-toc-title"> <i class="fas fa-folder-open"></i> Contents</h2>
    <div class="post-toc-content">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#序列特征">序列特征</a></li>
    <li><a href="#序列特征处理方法">序列特征处理方法</a>
      <ul>
        <li><a href="#pooling结构">$Pooling$结构</a></li>
        <li><a href="#attention结构">$Attention$结构</a>
          <ul>
            <li><a href="#din">$DIN$</a></li>
          </ul>
        </li>
        <li><a href="#rnn结构">$RNN$结构</a>
          <ul>
            <li><a href="#dien">$DIEN$</a></li>
          </ul>
        </li>
        <li><a href="#transformer结构">$Transformer$结构</a>
          <ul>
            <li><a href="#bst">$BST$</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#关于self-attention处理序列特征的讨论">关于self-attention处理序列特征的讨论</a></li>
    <li><a href="#总结">总结</a></li>
    <li><a href="#reference">$Reference$</a></li>
  </ul>
</nav>
    </div>
</div>
<script type="text/javascript">
    $(document).ready(function () {
        var postToc = $(".post-toc");
        if (postToc.length) {
            var leftPos = $("#main").offset().left;
            if (leftPos < 220) {
                postToc.css({ "width": leftPos - 10, "margin-left": (0 - leftPos) })
            }

            var t = postToc.offset().top - 20,
                a = {
                    start: {
                        position: "absolute",
                        top: t
                    },
                    process: {
                        position: "fixed",
                        top: 20
                    },
                };
            $(window).scroll(function () {
                var e = $(window).scrollTop();
                e < t ? postToc.css(a.start) : postToc.css(a.process)
            })
        }

        if ($("#TableOfContents").children().length < 1) {
            $(".post-toc").remove();
        }
    })
</script>
    <article class="post">
        <header>
            <h1 class="post-title">推荐算法中的序列特征处理</h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2022-02-08T00:00:00Z" class="post-meta meta-date dt-published">
    2022-02-08
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/RecSys' target="_blank">RecSys</a>
  
</div>


        
        
        <div class="post-content">
            <blockquote>
<p>在推荐领域中，行为序列特征是一种极为重要的特征。近年来，出现了很多有关行为序列特征建模的论文，研究如何将行为序列特征应用到推荐场景中，以更好挖掘用户的历史兴趣。本文将带大家梳理介绍这些论文中提出的方法。</p>
</blockquote>
<h2 id="序列特征">序列特征</h2>
<p>序列特征通常表现为时间上的跨度，具有很强的时间先后关系。如何在行为序列中挖掘用户兴趣的多样性以及实效性，是序列特模型研究的重点。</p>
<h2 id="序列特征处理方法">序列特征处理方法</h2>
<p>本文将聚焦于$Pooling、attention、transformer$等结构，介绍一些主流的序列特征的应用。</p>
<h3 id="pooling结构">$Pooling$结构</h3>
<p>基于$Pooling$结构的模型通常采用 $mean, sum$ 或者$ max\ pooling$ 的方法聚合行为序列，这种结构将序列中的每一个行为看得同等重要。 $Google$便曾通过基于$pooling$ 的操作建模用户的搜索序列、观看视频序列，应用在$Youtube$的视频推荐系统的召回和排序模块中。</p>
<p>在召回阶段的模型如下，使用了观看视频序列、搜索序列：</p>
<p>
        <img class="mx-auto" alt="" src="../img/DNN4Youtube.jpg" />   
    </p>
<p>由上图可以看出，最底层的输入是用户观看过的$video$的 $embedding$ 向量，以及搜索词的$embedding$向量，特征向量里面还包括了用户的地理位置的$embedding$，年龄，性别等。然后把所有这些特征$concatenate$起来，输入到上层的$ReLU$神经网络。最后经过 $softmax$ 函数得到最后输出。</p>
<p>在排序阶段的模型如下所示，使用了观看视频序列:</p>
<p>
        <img class="mx-auto" alt="" src="../img/DNN4Youtube1.jpg" />   
    </p>
<p>排序阶段引入另一套$DNN$作为$ranking\ model$的目的是为了引入更多描述视频、用户以及二者之间关系的特征，达到对候选视频集合准确排序的目的。</p>
<h3 id="attention结构">$Attention$结构</h3>
<p>基于$pooling$的方法中，将行为序列中的每个$Item$的重要性看作是相同的，无法区分历史行为中每个$Item$对当前待推荐$Item$的影响。对于不同的待排序物品，用户的兴趣向量也是相同的，无法建模多兴趣。</p>
<p>为了解决这些问题，研究者们提出了基于$Attention$结构建模行为序列的模型，主要包括 $DIN, DSTN$等。它们通过$attention$机制计算行为序列中的$Item$和待排序$Item$的$attention\ score $(即相关度)，作为序列中每个$Item$的权重，然后再将它们聚合起来。</p>
<h4 id="din">$DIN$</h4>
<p>DIN (Deep Interest Network for Click-Through Rate Prediction)由阿里妈妈的精准定向检索及基础算法团队提出。充分利用/挖掘用户历史行为数据中的信息来提高CTR预估的性能。</p>
<p>阿里的研究者们通过观察收集到的线上数据，发现了用户行为数据中有两个很重要的特性：</p>
<ul>
<li><strong>Diversity</strong>：用户在浏览电商网站的过程中显示出的兴趣是十分多样性的。</li>
<li><strong>Local activation</strong>: 由于用户兴趣的多样性，只有部分历史数据会影响到当次推荐的物品是否被点击，而不是所有的历史记录</li>
</ul>
<p>如何体现不同的历史行为的对当前推荐的item的参考价值呢，答案便是$attention$机制，这也是$DIN$模型的精髓所在。</p>
<p>注意力机制顾名思义，就是模型在预测的时候，对用户不同行为的注意力是不一样的，“相关”的行为历史看重一些，“不相关”的历史甚至可以忽略。那么这样的思想反应到模型中也是直观的。
$$
V_{u}=f\left(V_{a}\right)=\sum_{i=1}^{N} w_{i} * V_{i}=\sum_{i=1}^{N} g\left(V_{i}, V_{a}\right) * V_{i}
$$</p>
<p>上式中，$V_u$是用户的$embedding$向量, $V_a$是候选广告商品的$embedding$向量，$V_i$用户$u$的第$i$次行为的$embedding$向量，因为这里用户的行为就是浏览商品或店铺，所以行为的$embedding$的向量就是那次浏览的商品或店铺的$embedding$向量。</p>
<p>通过注意力机制，算出不同商品对当前待推荐的商品的影响权重，有效解决了<strong>Diversity</strong>和<strong>Local activation</strong>的问题。</p>
<p>$DIN$模型如下图所示：</p>
<p>
        <img class="mx-auto" alt="$DIN$" src="../img/DIN3.png" />   
    </p>
<p>$DIN$模型中，在$pooling$之前，与$candidate$相关的商品权重大一些，与$candidate$不相关的商品权重小一些，这是一种$Attention$的思想。将$candidate$与点击序列中的每个商品发生交互来计算$attention$分数。</p>
<p>具体计算方法如图中右上角所示，输入包括商品和$candidate$的$embedding$向量，以及两者的外积。对于不同的$candidate$，得到的用户表示向量也不同，具有更大的灵活性。</p>
<p>论文中还采用了一些其他的$trick$，比较重要的有以下几点：</p>
<ul>
<li>用$GAUC$这个离线metric替代$AUC$</li>
<li>用$Dice$方法替代经典的$PReLU$激活函数</li>
<li>介绍一种$Adaptive$的正则化方法</li>
</ul>
<h3 id="rnn结构">$RNN$结构</h3>
<p>采用$Attention$结构的模型，并没有考虑时间先后信息。按照经验，用户越新的行为，越能反应用户当时的兴趣，对于推测之后的行为所发挥的作用也越大，而旧的行为发挥的作用就弱一些，说明用户的兴趣在不断变化。</p>
<p>为了解决这些问题，研究者们提出了基于$RNN$建模行为序列，主要包括$DIEN, DUPN, HUP, DHAN$等。它们通过$RNN$建模行为序列的时间顺序特性，能更好地建模用户实时兴趣的变化。</p>
<h4 id="dien">$DIEN$</h4>
<p>$DIEN$基于双层$RNN(GRU)$来建模用户的商品点击序列，应用在电商APP推荐广告排序中。整体结构如下:</p>
<p>
        <img class="mx-auto" alt="$DIEN$" src="../img/DIEN.png" />   
    </p>
<p>传统的$RNN$存在着两个问题：</p>
<ul>
<li>在获取时序上用户兴趣表示的时候其实是将$RNN$的$hidden\ states$作为用户当前的一个$interests$，但是这个vector其实是缺少监督信息的，在计算$RNN$的$loss$时只有最后时刻的输出才会得到$target$的反应，也就是最后作为$target$的那个点击行为；</li>
<li>第二问题：我们知道RNN是用来获取不同时间行为的依赖性的，也就是说在时间序列上如果行为之间有很好的关联依赖性，那么RNN可以发挥很好的效果，但是对于用户行为来说可能在短时间内的就会有很多的点击行为，而且这些点击行为之间没有很好的依赖性，就比如我先点击一个衣服，又点击了一本书，两者之间依赖性不强，所以基于这两个问题，$DIEN$提出了两个网络结构来解决。</li>
</ul>
<p><strong>$Interest\ Extractor\ Layer$</strong></p>
<p>针对第一个关于问题，$DIEN$提出了$auxiliary\ loss$，如下图所示：</p>
<p>
        <img class="mx-auto" alt="$auxiliary\ loss$" src="../img/DIEN1.png" />   
    </p>
<p>$e(t+1)$是在$t+1$时刻用户点击的item的$embedding$，$h(t)$是用户在$t$时刻$GRU$的$hidden\ stats$，$e(t+1)^{\prime}$是经过负采样的用户没有点击的$item$，这样就一目了然了，$h(t)$代表了模型预测用户在$t+1$时刻的$interests$，而$e(t+1)$则是用户在$t+1$时刻真实的$interests$，这样做一个$inner\ product$ 来计算相似度，外边再加一层$sigmoid$，就得到了$auxiliary\ loss$，公式如下：
$$
\begin{aligned}
L_{a u x}=-&amp; \frac{1}{N}\left(\sum_{i=1}^{N} \sum_{t} \log \sigma\left(\mathbf{h}_{t}^{i}, \mathbf{e}_{b}^{i}[t+1]\right)\right.
\left.+\log \left(1-\sigma\left(\mathbf{h}_{t}^{i}, \hat{\mathbf{e}}_{b}^{i}[t+1]\right)\right)\right)
\end{aligned}
$$
然后模型的$total\ loss$就变成了$target\ loss + auxiliary\ loss$:
$$
L=L_{\text {target }}+\alpha * L_{a u x}
$$
<strong>$Interest\ Evolving\ Layer$</strong></p>
<p>针对第二个问题，$DEIN$网络提出了$AUGRU$的结构来解决传统的RNN时序依赖的问题:</p>
<p>
        <img class="mx-auto" alt="$AUGRU$" src="../img/DIEN2.png" />   
    
$$
\begin{aligned}
\tilde{\mathbf{u}}_{t}^{\prime} &amp;=a_{t} * \mathbf{u}_{t}^{\prime} \\
\mathbf{h}_{t}^{\prime} &amp;=\left(1-\tilde{\mathbf{u}}_{t}^{\prime}\right) \circ \mathbf{h}_{t-1}^{\prime}+\tilde{\mathbf{u}}_{t}^{\prime} \circ \tilde{\mathbf{h}}_{t}^{\prime}
\end{aligned}
$$</p>
<p>其实就是把$attention$计算的权重加了进来，整体的结构没有什么变化，但是这样其实是让时序中跟$target$不相近的$vector$给弱化掉，能够达到对于$target$兴趣进化的行为提取。</p>
<h3 id="transformer结构">$Transformer$结构</h3>
<p>自从$BERT$模型在$NLP$领域大放异彩之后，$transfomer$结构似乎成为文本序列模型的标配。自然的，将$transfomer$引入到行为序列的建模中，也逐步成为工业界搜索推荐行为序列建模的主流，主要工作包括 BST, DSIN, SIM, DMT 等。</p>
<p>
        <img class="mx-auto" alt="$transformer$" src="../img/transformer.jpg" />   
    </p>
<h4 id="bst">$BST$</h4>
<p>$BST$ 基于$Transformer$建模行为序列，用于电商APP推荐。 BST 的模型结构主要是由 Embedding 层，Transformer 层与 MLP 层组成，如下图所示：</p>
<p>
        <img class="mx-auto" alt="$BST$" src="../img/BST.png" />   
    </p>
<p>$Embedding$层主要分为 $Other\ Features, User\ Behavior\ Sequence, Target\ Item$,</p>
<ul>
<li>$Other\ Features$主要包括用户的基本特征、目标物品的基本特征、上下文信息、交叉特征等，先将每个大的种类特征内的所有内容进行拼接，再分别进行embedding映射为一个低维向量，最后得到一个$embedding$矩阵。</li>
<li>$User\ Behavior\ Sequence$：包含$Positional\ Feature$ 和 $Sequence\ Item\ Features$。</li>
</ul>
<p>需要注意的是，$BST$中并没有采用$Transfomer$原始论文中所使用的正余弦位置编码方法，而是使用了相对时间差作为$position\ embedding$:
$$
\operatorname{pos}\left(v_{i}\right)=t\left(v_{t}\right)-t\left(v_{i}\right)
$$
$BST$比较直接的将 $Transformer$应用到推荐系统中，通过引入$Transformer\ Layer$来很好的利用了用户历史行为序列信息，最终在淘宝的数据集上取得了很好的效果。</p>
<h2 id="关于self-attention处理序列特征的讨论">关于self-attention处理序列特征的讨论</h2>
<p>在使用self-attention机制处理序列特征时，$Target\ item$如何处理, 目前有两种比较主流的方法</p>
<ul>
<li>将$target\_item$ append到原序列特征的尾部，当成序列特征的一部分，进行self-attention的计算</li>
</ul>
<p>
        <img class="mx-auto" alt="" src="https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/seq1.png" />   
    </p>
<ul>
<li>先对原始序列特征进行$self-attention$的计算，然后和$target\_item$进行$target\_attention$计算(DIN)

        <img class="mx-auto" alt="" src="https://markdown-1258220306.cos.ap-shenzhen-fsi.myqcloud.com/img/seq2.png" />   
    </li>
</ul>
<h2 id="总结">总结</h2>
<p>序列特征是一种很强的反应用户历史兴趣的特征，因此，如何有效的对其进行表征，是推荐模型中的重要一环。好的序列模型将极大的提升推荐的效果。$Pooling、Attention、Transformer$等结构都是目前比较成熟的应用。此外，关于<strong>长期序列(MIMN, SIM)</strong>、<strong>多行为序列(MKM-SR)</strong> 和 <strong>多兴趣表示(MIND,ComiRec)</strong> 等多个角度的序列建模，都取得了不错的研究成果。</p>
<h2 id="reference">$Reference$</h2>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/51623339">推荐系统中的注意力机制——阿里深度兴趣网络(DIN)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/299585179">推荐系统 DIEN (Deep Interest Evolution Network)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/78365283">从DIN到DIEN看阿里CTR算法的进化脉络</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/389044011">《推荐系统》系列之五：序列推荐</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/461393899">序列特征在推荐算法中的应用</a></li>
<li>Deep neural networks for youtube recommendations</li>
<li>Zhou G, Zhu X, Song C, et al. Deep interest network for click-through rate prediction</li>
<li>Deep interest evolution network for click-through rate prediction.</li>
<li>Behavior sequence transformer for e-commerce recommendation in alibaba</li>
<li>Chang J, Gao C, Zheng Y, et al. Sequential Recommendation with Graph Neural Networks</li>
<li>Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need</li>
</ol>

        </div>

        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='/tags/%E6%8E%A8%E8%8D%90' target="_blank">推荐 </a></li>
                
                <li><a href='/tags/%E5%BA%8F%E5%88%97%E7%89%B9%E5%BE%81' target="_blank">序列特征 </a></li>
                
            </ul>
            
        </div>

        <style>
            hr {
                opacity: 0.5;  
                border: none;  
                height: 1px;  
                background-color: rgba(101, 91, 91, 0.422);  
            }
        </style>

        <hr>


        
    

    
    
    
    
    
    <div id="waline"></div>
    <script type="module">
      import { init } from 'https://unpkg.com/@waline/client@v2/dist/waline.mjs';

      init({
        el: "#waline",
        
        serverURL: "https:\/\/white-waline.netlify.app\/.netlify\/functions\/comment",
        lang: "zh-CN",
        placeholder: "说点什么吧..."
        
      });
    </script>
    
        
        
        
        


    </article>
</div>

                    <footer id="footer">
    <div>
        &copy; 2024 <a href="https://whiteding.fun/">White By whiteding</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>





<style type="text/css">
div.highlight {
    position: relative;
    margin: 1em 0px;
}

.copy-code {
    display: none;
    position: absolute;
    top: 4px;
    right: 4px;
    color: rgba(255, 255, 255, 0.8);
    background: rgba(78, 78, 78, 0.8);
    border-radius: var(--radius);
    padding: 0 5px;
    font: inherit;
    user-select: none;
    cursor: pointer;
    border: 0;
    --radius: 8px;
}

div.highlight:hover .copy-code,pre:hover .copy-code {
    display: block;
}

</style>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>





    <script src='/js/douban.js'></script>




    <script src="https://unpkg.com/@waline/client@v2/dist/waline.mjs"></script>

                </div>

                <div id="secondary">
    
    

    <section class="widget">
        
<div class="avatar-widget">
    <img src="/img/avatar3.png" alt="Avatar" class="avatar-image">

    <p class="avatar-slogan">What's past is prologue.</p>
    <div class="widget-list" style="display: flex" >
        
        <li>
            <a class="info-icon" href="mailto:white_ding@163.com" title="email" target="_blank" style="margin-inline:5px">
                <i class="fa fa-envelope-square fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
        <li>
            <a class="info-icon" href="https://www.linkedin.com/in/white-ding-7b5151a7/" title="linkedin" target="_blank" style="margin-inline:5px">
                <i class="fab fa-linkedin fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
        <li>
            <a class="info-icon" href="https://github.com/Shu-HowTing" title="github" target="_blank" style="margin-inline:5px">
                <i class="fab fa-github fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
    </div>
</div>



    </section>

    <section class="widget">
        <h3 class="widget-title"> <i class="far fa-file"></i> Latest articles</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%BD%93%E6%8E%A8%E8%8D%90%E9%81%87%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="当推荐遇到大模型" target="_blank">当推荐遇到大模型</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/Batch%E8%B4%9F%E9%87%87%E6%A0%B7/" title="Batch内负采样" target="_blank">Batch内负采样</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%8A%A8%E6%80%81%E6%9D%83%E9%87%8D/" title="动态权重在推荐中的应用" target="_blank">动态权重在推荐中的应用</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/POSO%E5%86%B7%E5%90%AF%E5%8A%A8/" title="POSO冷启动" target="_blank">POSO冷启动</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/" title="推荐中的特征交叉技术" target="_blank">推荐中的特征交叉技术</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/machine_learning/ordinal_regression/" title="Ordinal Regression" target="_blank">Ordinal Regression</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0/" title="召回模型的评估" target="_blank">召回模型的评估</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%A4%9A%E5%85%B4%E8%B6%A3%E5%8F%AC%E5%9B%9E%E6%8E%A8%E8%8D%90/" title="多兴趣召回推荐" target="_blank">多兴趣召回推荐</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%8D%9F%E5%A4%B1%E4%BC%98%E5%8C%96/" title="多任务loss优化" target="_blank">多任务loss优化</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/seq_feat/" title="推荐算法中的序列特征处理" target="_blank">推荐算法中的序列特征处理</a>
    </li>
    
</ul>
    </section>

     
    

    <section class="widget">
        <h3 class="widget-title"><a href='/categories/'> <i class="far fa-folder"></i> Categories</a></h3>
<ul class="widget-list">
    
    <li><a href="https://whiteding.fun/categories/RecSys/">RecSys (9)</a></li>
    
    <li><a href="https://whiteding.fun/categories/deep-learning/">deep learning (3)</a></li>
    
    <li><a href="https://whiteding.fun/categories/flink/">flink (1)</a></li>
    
    <li><a href="https://whiteding.fun/categories/kafka/">kafka (1)</a></li>
    
    <li><a href="https://whiteding.fun/categories/machine-learning/">machine learning (5)</a></li>
    
    <li><a href="https://whiteding.fun/categories/spark/">spark (12)</a></li>
    
    <li><a href="https://whiteding.fun/categories/statistics/">statistics (2)</a></li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href='/tags/'> <i class="fas fa-tag"></i> Tags</a></h3>
<div class="tagcloud">
    
    <a href="https://whiteding.fun/tags/Beta%E5%88%86%E5%B8%83/">Beta分布</a>
    
    <a href="https://whiteding.fun/tags/CUPED/">CUPED</a>
    
    <a href="https://whiteding.fun/tags/FM/">FM</a>
    
    <a href="https://whiteding.fun/tags/Regression/">Regression</a>
    
    <a href="https://whiteding.fun/tags/Thompson/">Thompson</a>
    
    <a href="https://whiteding.fun/tags/flink/">flink</a>
    
    <a href="https://whiteding.fun/tags/kafka/">kafka</a>
    
    <a href="https://whiteding.fun/tags/multi-task/">multi-task</a>
    
    <a href="https://whiteding.fun/tags/rank/">rank</a>
    
    <a href="https://whiteding.fun/tags/softmax/">softmax</a>
    
    <a href="https://whiteding.fun/tags/spark/">spark</a>
    
    <a href="https://whiteding.fun/tags/transformer/">transformer</a>
    
    <a href="https://whiteding.fun/tags/xgb/">xgb</a>
    
    <a href="https://whiteding.fun/tags/%E5%86%B7%E5%90%AF%E5%8A%A8/">冷启动</a>
    
    <a href="https://whiteding.fun/tags/%E5%8F%AC%E5%9B%9E/">召回</a>
    
    <a href="https://whiteding.fun/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a>
    
    <a href="https://whiteding.fun/tags/%E5%BA%8F%E5%88%97%E7%89%B9%E5%BE%81/">序列特征</a>
    
    <a href="https://whiteding.fun/tags/%E6%8E%A8%E8%8D%90/">推荐</a>
    
    <a href="https://whiteding.fun/tags/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/">特征交叉</a>
    
    <a href="https://whiteding.fun/tags/%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7/">特征重要性</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title"> <i class="fas fa-external-link-alt"></i> Links</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="https://www.instagram.com/whiteding94/" title="instagram"> <i class="fab fa-instagram fa-lg"></i> Instagram</a>
        </li>
        
        <li>
            <a target="_blank" href="https://www.zhihu.com/people/ding-shu-hao" title="blog"> <i class="far fa-comment fa-lg"></i> 知乎</a>
        </li>
        
    </ul>
</section>


    
</div>

            </div>
        </div>
    </div>

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
</body>

</html>