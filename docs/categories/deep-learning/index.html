<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <meta name="referrer" content="no-referrer-when-downgrade">
    

    <title>deep learning | White</title>
    <meta property="og:title" content="deep learning - White">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="DS, DeepLearning">
    <meta name="description" content="deep learning">
        
    <meta name="author" content="whiteding">
    <meta property="og:url" content="https://whiteding.fun/categories/deep-learning/">
    <link rel="shortcut icon" href='/favicon.ico'  type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml" href="https://whiteding.fun/categories/deep-learning/index.xml" title="White" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
        <link rel="stylesheet" href='/css/douban.css'>
    
        <link rel="stylesheet" href='/css/other.css'>
    

    
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@waline/client@v2/dist/waline.css">
        
    


</head>

<body>
    
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://whiteding.fun/">
                        White
                    </a>
                
                <p class="description">Stay foolish, Stay hungry!</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://whiteding.fun/"> <i class="fas fa-home"></i> Home</a>
                    
                    <a  href="/categories/" title="&lt;i class=&#39;fas fa-layer-group&#39;&gt;&lt;/i&gt; 分类" > <i class='fas fa-layer-group'></i> 分类</a>
                    
                    
                    <a  href="/tags/" title="&lt;i class=&#39;fas fa-tag&#39;&gt;&lt;/i&gt; 标签" > <i class='fas fa-tag'></i> 标签</a>
                    
                    
                    <a  href="/archives/" title="&lt;i class=&#39;fas fa-archive&#39;&gt;&lt;/i&gt; 归档" > <i class='fas fa-archive'></i> 归档</a>
                    
                    
                    <a  href="/about/" title="&lt;i class=&#39;fas fa-user&#39;&gt;&lt;/i&gt; 关于" > <i class='fas fa-user'></i> 关于</a>
                    
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <h3 class="archive-title">
        分类
        <span class="keyword">deep learning</span>
        articles
    </h3>
    

    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/deep_learning/transformer%E7%9A%84%E7%BB%86%E8%8A%82%E7%90%86%E8%A7%A3/" target="_blank">Transformer的细节</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2021-12-10T00:00:00Z" class="post-meta meta-date dt-published">
    2021-12-10
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/deep-learning' target="_blank">deep learning</a>
  
</div>


        <div class="post-content">
            Transformer中的几个细节讨论 1. 为什么self-attention中需要$/\sqrt{d}$ 在自注意力（self-attention）机制中，将查询（Query, Q）与键（Key, K）相乘之后除以($\sqrt{d}$)，其中d是键向量的维度，这是为了稳定梯度和防止数值不稳定。 具体原因如下： 避免数值过大：在没有缩放的情况下，Q和K的点积结果会随着维度$d$的增加而变得很大。点积的结果会随……
            <p class="readmore"><a href="https://whiteding.fun/post/deep_learning/transformer%E7%9A%84%E7%BB%86%E8%8A%82%E7%90%86%E8%A7%A3/" target="_blank">阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/deep_learning/transformer%E5%85%A5%E9%97%A8/" target="_blank">Transformer模型理解</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2021-11-15T00:00:00Z" class="post-meta meta-date dt-published">
    2021-11-15
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/deep-learning' target="_blank">deep learning</a>
  
</div>


        <div class="post-content">
            Transformer模型在2017年被google提出，直接基于Self-Attention结构，并且迅速取代了之前NLP任务中常用的RNN神经网络结构，成为主流。本文将探讨关于transformer模型的行馆细节 Transformer Encoder Self-attention $$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $$ Transformer 中token的输入表示$a$由$Word\ Embedding$ 和位置 $Positional\ Encoding$ 相加得到。 Add &amp; Norm Add &amp; Norm 层由 Add 和 Norm 两部分组成，其计算公式如下： $$\textit{LayerNorm}\big(X+\text{MultiHeadAttention}(X)\big)$$ Feed Forward Feed Forward 层比较简单，是一个两层的全连接层，第一……
            <p class="readmore"><a href="https://whiteding.fun/post/deep_learning/transformer%E5%85%A5%E9%97%A8/" target="_blank">阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://whiteding.fun/post/deep_learning/softmax%E4%B8%AD%E6%B8%A9%E5%BA%A6%E7%B3%BB%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8/" target="_blank">对比损失中温度系数的作用</a>
            </h1>
        </header>
        
  <i class="far fa-calendar-alt fa-sm"></i> 
  <time datetime="2021-05-15T00:00:00Z" class="post-meta meta-date dt-published">
    2021-05-15
  </time>


<div class="post-meta meta-category">
  <span>&nbsp;|</span>
  
    <i class="far fa-folder fa-sm"></i> 
    <a href='/categories/deep-learning' target="_blank">deep learning</a>
  
</div>


        <div class="post-content">
            温度系数 对比损失（Contrastive Loss）中的参数$\tau$是一个神秘的参数，大部分论文都默认采用较小的值来进行自监督对比学习（例如 $\tau = 0.05$），但是很少有文章详细讲解参数$\tau$的作用，本文将详解对比损失中的超参数 ，并借此分析对比学习的核心机制。 首先总结下本文的发现： 对比损失是一个具备困难负样本自发现性质的损失函数，这一性质对于学习高质量的自监督表示是至关重要的。关注困难样本的……
            <p class="readmore"><a href="https://whiteding.fun/post/deep_learning/softmax%E4%B8%AD%E6%B8%A9%E5%BA%A6%E7%B3%BB%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8/" target="_blank">阅读全文 <i class="fas fa-chevron-right fa-sm"></i> </a></p>
        </div>
    </article>
    

    





</div>

                    <footer id="footer">
    <div>
        &copy; 2024 <a href="https://whiteding.fun/">White By whiteding</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>










    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




    <script src='/js/douban.js'></script>




    <script src="https://unpkg.com/@waline/client@v2/dist/waline.mjs"></script>

                </div>

                <div id="secondary">
    
    

    <section class="widget">
        
<div class="avatar-widget">
    <img src="/img/avatar3.png" alt="Avatar" class="avatar-image">

    <p class="avatar-slogan">What's past is prologue.</p>
    <div class="widget-list" style="display: flex" >
        
        <li>
            <a class="info-icon" href="mailto:white_ding@163.com" title="email" target="_blank" style="margin-inline:5px">
                <i class="fa fa-envelope-square fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
        <li>
            <a class="info-icon" href="https://www.linkedin.com/in/white-ding-7b5151a7/" title="linkedin" target="_blank" style="margin-inline:5px">
                <i class="fab fa-linkedin fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
        <li>
            <a class="info-icon" href="https://github.com/Shu-HowTing" title="github" target="_blank" style="margin-inline:5px">
                <i class="fab fa-github fa-lg" style="margin-inline:8px"></i>
            </a>
        </li>
        
    </div>
</div>



    </section>

    <section class="widget">
        <h3 class="widget-title"> <i class="far fa-file"></i> Latest articles</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%BD%93%E6%8E%A8%E8%8D%90%E9%81%87%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="当推荐遇到大模型" target="_blank">当推荐遇到大模型</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/Batch%E8%B4%9F%E9%87%87%E6%A0%B7/" title="Batch内负采样" target="_blank">Batch内负采样</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%8A%A8%E6%80%81%E6%9D%83%E9%87%8D/" title="动态权重在推荐中的应用" target="_blank">动态权重在推荐中的应用</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/" title="推荐中的特征交叉技术" target="_blank">推荐中的特征交叉技术</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0/" title="召回模型的评估" target="_blank">召回模型的评估</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/%E5%A4%9A%E5%85%B4%E8%B6%A3%E5%8F%AC%E5%9B%9E%E6%8E%A8%E8%8D%90/" title="多兴趣召回推荐" target="_blank">多兴趣召回推荐</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/recsys/seq_feat/" title="推荐算法中的序列特征处理" target="_blank">推荐算法中的序列特征处理</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/deep_learning/transformer%E7%9A%84%E7%BB%86%E8%8A%82%E7%90%86%E8%A7%A3/" title="Transformer的细节" target="_blank">Transformer的细节</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/machine_learning/softmax%E8%AE%A1%E7%AE%97%E4%BC%98%E5%8C%96/" title="softmax计算优化" target="_blank">softmax计算优化</a>
    </li>
    
    <li>
        <a href="https://whiteding.fun/post/deep_learning/transformer%E5%85%A5%E9%97%A8/" title="Transformer模型理解" target="_blank">Transformer模型理解</a>
    </li>
    
</ul>
    </section>

     
    

    <section class="widget">
        <h3 class="widget-title"><a href='/categories/'> <i class="far fa-folder"></i> Categories</a></h3>
<ul class="widget-list">
    
    <li><a href="https://whiteding.fun/categories/RecSys/">RecSys (7)</a></li>
    
    <li><a href="https://whiteding.fun/categories/deep-learning/">deep learning (3)</a></li>
    
    <li><a href="https://whiteding.fun/categories/flink/">flink (1)</a></li>
    
    <li><a href="https://whiteding.fun/categories/kafka/">kafka (1)</a></li>
    
    <li><a href="https://whiteding.fun/categories/machine-learning/">machine learning (3)</a></li>
    
    <li><a href="https://whiteding.fun/categories/spark/">spark (12)</a></li>
    
    <li><a href="https://whiteding.fun/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学 (1)</a></li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href='/tags/'> <i class="fas fa-tag"></i> Tags</a></h3>
<div class="tagcloud">
    
    <a href="https://whiteding.fun/tags/Beta%E5%88%86%E5%B8%83/">Beta分布</a>
    
    <a href="https://whiteding.fun/tags/Thompson/">Thompson</a>
    
    <a href="https://whiteding.fun/tags/flink/">flink</a>
    
    <a href="https://whiteding.fun/tags/kafka/">kafka</a>
    
    <a href="https://whiteding.fun/tags/rank/">rank</a>
    
    <a href="https://whiteding.fun/tags/softmax/">softmax</a>
    
    <a href="https://whiteding.fun/tags/spark/">spark</a>
    
    <a href="https://whiteding.fun/tags/transformer/">transformer</a>
    
    <a href="https://whiteding.fun/tags/xgb/">xgb</a>
    
    <a href="https://whiteding.fun/tags/%E5%8F%AC%E5%9B%9E/">召回</a>
    
    <a href="https://whiteding.fun/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a>
    
    <a href="https://whiteding.fun/tags/%E5%BA%8F%E5%88%97%E7%89%B9%E5%BE%81/">序列特征</a>
    
    <a href="https://whiteding.fun/tags/%E6%8E%A8%E8%8D%90/">推荐</a>
    
    <a href="https://whiteding.fun/tags/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/">特征交叉</a>
    
    <a href="https://whiteding.fun/tags/%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7/">特征重要性</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title"> <i class="fas fa-external-link-alt"></i> Links</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="https://www.instagram.com/whiteding94/" title="instagram"> <i class="fab fa-instagram fa-lg"></i> Instagram</a>
        </li>
        
        <li>
            <a target="_blank" href="https://www.zhihu.com/people/ding-shu-hao" title="blog"> <i class="far fa-comment fa-lg"></i> 知乎</a>
        </li>
        
    </ul>
</section>


    
</div>

            </div>
        </div>
    </div>

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
</body>

</html>